{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 0.23638484954833985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "cross_entropy = mod.get_function(\"cross_entropy\")\n",
    "reduce = mod.get_function(\"reduce\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "num_classes = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "probs = np.random.rand(n, num_classes).astype(np.float32).flatten()\n",
    "y = np.random.randint(0, num_classes, n).astype(np.int32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "probs_gpu = drv.mem_alloc(probs.nbytes)\n",
    "y_gpu = drv.mem_alloc(y.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(probs_gpu, probs)\n",
    "drv.memcpy_htod(y_gpu, y)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 32\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel cross_entropy\n",
    "cross_entropy(probs_gpu, y_gpu, out_gpu, np.int32(n), np.int32(num_classes), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Allouer de la mémoire pour la réduction\n",
    "temp_o = np.zeros(grid_size, dtype=np.float32)\n",
    "temp_o_gpu = drv.mem_alloc(temp_o.nbytes)\n",
    "\n",
    "# Lancer le kernel reduce\n",
    "reduce(out_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * out.dtype.itemsize)\n",
    "\n",
    "# Réduire jusqu'à obtenir un seul résultat\n",
    "while grid_size > 1:\n",
    "    n = grid_size\n",
    "    grid_size = (n + block_size - 1) // block_size\n",
    "    reduce(temp_o_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * out.dtype.itemsize)\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(temp_o, temp_o_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Cross Entropy Loss:\", temp_o[0]/len(probs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WX: [0.44234893 0.9506427  0.816055   0.76536775 0.7407418  0.6851173\n",
      " 0.17310758 0.22000445 0.38997483 0.09695225]\n",
      "b: [0.56816417 0.6982709  0.27382904 0.12475282 0.8154408  0.2197792\n",
      " 0.9319359  0.79871154 0.49813652 0.5260788 ]\n",
      "out: [1.0105131  1.6489136  1.089884   0.89012057 1.5561826  0.9048965\n",
      " 1.1050435  1.018716   0.88811135 0.6230311 ]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "add = mod.get_function(\"add\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "WX = np.random.rand(n).astype(np.float32)\n",
    "b = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "WX_gpu = drv.mem_alloc(WX.nbytes)\n",
    "b_gpu = drv.mem_alloc(b.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(WX_gpu, WX)\n",
    "drv.memcpy_htod(b_gpu, b)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "add(WX_gpu, b_gpu, out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"WX:\", WX)\n",
    "print(\"b:\", b)\n",
    "print(\"out:\", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0.1489793  0.44899675 0.15992235 0.46268043 0.82906663 0.965229\n",
      " 0.28252417 0.6692759  0.35778728 0.94535726]\n",
      "out: [0.5371761  0.6104007  0.5398956  0.61364985 0.6961576  0.7241675\n",
      " 0.570165   0.661341   0.5885047  0.7201805 ]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "sigmoid = mod.get_function(\"sigmoid\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "X = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "X_gpu = drv.mem_alloc(X.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(X_gpu, X)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "sigmoid(X_gpu, out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"X:\", X)\n",
    "print(\"out:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0.7726385  0.31193995 0.02944737 0.6629064  0.7248422  0.20570233\n",
      " 0.59993666 0.90065956 0.67544335 0.272483  ]\n",
      "exp_scores: [2.1654725 1.3660727 1.0298853 1.9404238 2.0644052 1.2283875 1.8220034\n",
      " 2.461226  1.9649038 1.3132211]\n",
      "softmax_out: [0.12476794 0.07870895 0.05933886 0.11180132 0.11894475 0.07077595\n",
      " 0.10497829 0.14180836 0.11321178 0.07566381]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "exp_scores = mod.get_function(\"exp_scores\")\n",
    "softmax_div = mod.get_function(\"softmax_div\")\n",
    "reduce = mod.get_function(\"reduce\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "X = np.random.rand(n).astype(np.float32)\n",
    "exp_scores_out = np.zeros(n, dtype=np.float32)\n",
    "softmax_out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "X_gpu = drv.mem_alloc(X.nbytes)\n",
    "exp_scores_gpu = drv.mem_alloc(exp_scores_out.nbytes)\n",
    "softmax_out_gpu = drv.mem_alloc(softmax_out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(X_gpu, X)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel exp_scores\n",
    "exp_scores(X_gpu, exp_scores_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Allouer de la mémoire pour la réduction\n",
    "temp_o = np.zeros(grid_size, dtype=np.float32)\n",
    "temp_o_gpu = drv.mem_alloc(temp_o.nbytes)\n",
    "drv.memcpy_dtoh(exp_scores_out,exp_scores_gpu )\n",
    "# Lancer le kernel reduce\n",
    "reduce(exp_scores_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * exp_scores_out.dtype.itemsize)\n",
    "\n",
    "# Réduire jusqu'à obtenir un seul résultat\n",
    "while grid_size > 1:\n",
    "    n = grid_size\n",
    "    grid_size = (n + block_size - 1) // block_size\n",
    "    reduce(temp_o_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * temp_o.dtype.itemsize)\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(temp_o, temp_o_gpu)\n",
    "sum_exp_scores = temp_o[0]\n",
    "\n",
    "# Lancer le kernel softmax_div\n",
    "softmax_div(exp_scores_gpu, np.float32(sum_exp_scores), softmax_out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(softmax_out, softmax_out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"X:\", X)\n",
    "print(\"exp_scores:\", exp_scores_out)\n",
    "print(\"softmax_out:\", softmax_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs: [[0.99579984 0.5844601  0.33910036 0.49083814 0.04340772]\n",
      " [0.58158123 0.03585429 0.240528   0.6326014  0.11575428]\n",
      " [0.49828082 0.6637241  0.93154335 0.36431745 0.38215813]\n",
      " [0.375357   0.35834676 0.72663724 0.08556011 0.49493223]\n",
      " [0.13543361 0.9085487  0.7289106  0.7970793  0.82219565]\n",
      " [0.32560155 0.8896485  0.9166291  0.33301947 0.16918373]\n",
      " [0.41824257 0.56029624 0.9962488  0.856241   0.6235782 ]\n",
      " [0.05035216 0.5427813  0.21113048 0.30545023 0.12998605]\n",
      " [0.0427946  0.06538843 0.15667163 0.78847784 0.96960974]\n",
      " [0.72211444 0.12521063 0.03835817 0.12172013 0.04630733]]\n",
      "y_true: [3 2 2 3 3 4 2 3 0 0]\n",
      "out: [[ 0.99579984  0.5844601   0.33910036 -0.50916183  0.04340772]\n",
      " [ 0.58158123  0.03585429 -0.759472    0.6326014   0.11575428]\n",
      " [ 0.49828082  0.6637241  -0.06845665  0.36431745  0.38215813]\n",
      " [ 0.375357    0.35834676  0.72663724 -0.9144399   0.49493223]\n",
      " [ 0.13543361  0.9085487   0.7289106  -0.20292068  0.82219565]\n",
      " [ 0.32560155  0.8896485   0.9166291   0.33301947 -0.83081627]\n",
      " [ 0.41824257  0.56029624 -0.00375122  0.856241    0.6235782 ]\n",
      " [ 0.05035216  0.5427813   0.21113048 -0.6945498   0.12998605]\n",
      " [-0.9572054   0.06538843  0.15667163  0.78847784  0.96960974]\n",
      " [-0.27788556  0.12521063  0.03835817  0.12172013  0.04630733]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_delta2 = mod.get_function(\"compute_delta2\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "num_classes = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "probs = np.random.rand(n, num_classes).astype(np.float32).flatten()\n",
    "y_true = np.random.randint(0, num_classes, n).astype(np.int32)\n",
    "out = np.zeros((n, num_classes), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "probs_gpu = drv.mem_alloc(probs.nbytes)\n",
    "y_true_gpu = drv.mem_alloc(y_true.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(probs_gpu, probs)\n",
    "drv.memcpy_htod(y_true_gpu, y_true)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_delta2(probs_gpu, y_true_gpu, out_gpu, np.int32(num_classes), np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"probs:\", probs.reshape(n, num_classes))\n",
    "print(\"y_true:\", y_true)\n",
    "print(\"out:\", out.reshape(n, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input matrix:\n",
      "[[0.5700534  0.39107805 0.8774503 ]\n",
      " [0.925321   0.07030687 0.00256335]\n",
      " [0.8592909  0.6232187  0.5291981 ]\n",
      " [0.85796773 0.8749382  0.9951363 ]]\n",
      "Transposed matrix:\n",
      "[[0.5700534  0.925321   0.8592909  0.85796773]\n",
      " [0.39107805 0.07030687 0.6232187  0.8749382 ]\n",
      " [0.8774503  0.00256335 0.5291981  0.9951363 ]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "transpose = mod.get_function(\"transpose\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "nx = 4\n",
    "ny = 3\n",
    "\n",
    "# Générer des données d'exemple\n",
    "in_data = np.random.rand(nx, ny).astype(np.float32).flatten()\n",
    "out_data = np.zeros((ny, nx), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "in_gpu = drv.mem_alloc(in_data.nbytes)\n",
    "out_gpu = drv.mem_alloc(out_data.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(in_gpu, in_data)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = (16, 16, 1)\n",
    "grid_size = ((nx + block_size[0] - 1) // block_size[0], (ny + block_size[1] - 1) // block_size[1])\n",
    "\n",
    "# Lancer le kernel\n",
    "transpose(in_gpu, out_gpu, np.int32(nx), np.int32(ny), block=block_size, grid=grid_size)\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out_data, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Input matrix:\")\n",
    "print(in_data.reshape(nx, ny))\n",
    "print(\"Transposed matrix:\")\n",
    "print(out_data.reshape(ny, nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta2: [[9.6142030e-01 3.0700335e-01 8.9189118e-01 4.1769958e-01 8.9025557e-01]\n",
      " [4.5738357e-01 4.4079411e-01 6.6005242e-01 3.0428696e-01 7.6815319e-01]\n",
      " [3.7232322e-01 8.7078130e-01 3.5921535e-01 8.0106628e-01 6.6981053e-01]\n",
      " [3.1943254e-02 9.3578267e-01 6.9587469e-01 7.1866101e-01 4.1000751e-01]\n",
      " [1.0383261e-01 5.5926764e-01 4.8642412e-01 5.7543546e-01 7.5620651e-01]\n",
      " [3.1661743e-01 6.2468380e-01 8.2727581e-01 8.9099240e-01 8.4367818e-01]\n",
      " [4.6844202e-01 9.9610591e-01 4.8065805e-01 8.5665178e-01 6.9197929e-01]\n",
      " [7.5416809e-01 5.6775284e-01 6.2161505e-01 6.1623162e-01 5.4685020e-01]\n",
      " [5.8293217e-01 4.1602081e-01 3.6674398e-01 6.7336714e-01 1.7571448e-04]\n",
      " [8.1068653e-01 7.4544173e-01 6.8225920e-01 9.1511422e-01 6.9846046e-01]]\n",
      "out: [3.4682698 2.6306703 3.0731966 2.7922692 2.4811664 3.5032477 3.4938369\n",
      " 3.1066177 2.0392396 3.851962 ]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_db2 = mod.get_function(\"compute_db\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "delta2 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros(n_row, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "delta2_gpu = drv.mem_alloc(delta2.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(delta2_gpu, delta2)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_db2(delta2_gpu, out_gpu, np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"delta2:\", delta2.reshape(n_row, n_col))\n",
    "print(\"out:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta1: [[0.7229435  0.7954493  0.8658877  0.4679509  0.11311023]\n",
      " [0.06317025 0.54869056 0.38638923 0.02145014 0.17736492]\n",
      " [0.0269344  0.2003111  0.70101446 0.8266686  0.8926484 ]\n",
      " [0.1969392  0.7548375  0.36957484 0.50805146 0.82041967]\n",
      " [0.36999398 0.87921983 0.83923465 0.8131322  0.82500696]\n",
      " [0.789612   0.7683042  0.37008485 0.858343   0.58363235]\n",
      " [0.29557848 0.6855353  0.08448109 0.17226145 0.07810096]\n",
      " [0.75133127 0.92027587 0.8284486  0.53703386 0.27873248]\n",
      " [0.24790819 0.202245   0.43571332 0.567349   0.42123634]\n",
      " [0.50979376 0.99081457 0.17006712 0.8927718  0.26770726]]\n",
      "z1: [[0.18454328 0.08837061 0.74219215 0.1754119  0.11132077]\n",
      " [0.12701088 0.3263054  0.83915436 0.7290275  0.12473806]\n",
      " [0.70479375 0.6269907  0.59244823 0.99271196 0.83478093]\n",
      " [0.7525487  0.3677572  0.27071783 0.01353576 0.71301556]\n",
      " [0.4139638  0.31022763 0.47929388 0.556638   0.7373239 ]\n",
      " [0.6445809  0.8070839  0.17222428 0.19873093 0.25994596]\n",
      " [0.82396036 0.4758171  0.08085154 0.6257178  0.77216405]\n",
      " [0.29462793 0.46332905 0.2142767  0.26325002 0.10377345]\n",
      " [0.4536034  0.10591054 0.4047887  0.5288883  0.13110124]\n",
      " [0.19389987 0.8436496  0.23973867 0.14231753 0.8851326 ]]\n",
      "out: [[0.17920576 0.19847459 0.18919872 0.11609241 0.02819013]\n",
      " [0.01572904 0.1335851  0.08140535 0.00470869 0.04416919]\n",
      " [0.00596205 0.04546154 0.16073218 0.16307954 0.18839084]\n",
      " [0.04287283 0.18246998 0.09072133 0.12700705 0.18109618]\n",
      " [0.08864622 0.21460007 0.19820596 0.18831533 0.180577  ]\n",
      " [0.17823912 0.16390422 0.09183852 0.21248092 0.14347076]\n",
      " [0.06264645 0.16203804 0.0210858  0.03911064 0.01688138]\n",
      " [0.18381484 0.21815023 0.20475286 0.13195902 0.06949586]\n",
      " [0.05889523 0.05041973 0.10458533 0.13236322 0.10485788]\n",
      " [0.12625799 0.20837434 0.04191168 0.2220666  0.05535756]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_delta1 = mod.get_function(\"compute_delta1\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "delta1 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "z1 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros((n_row, n_col), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "delta1_gpu = drv.mem_alloc(delta1.nbytes)\n",
    "z1_gpu = drv.mem_alloc(z1.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(delta1_gpu, delta1)\n",
    "drv.memcpy_htod(z1_gpu, z1)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_delta1(delta1_gpu, z1_gpu, out_gpu, np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"delta1:\", delta1.reshape(n_row, n_col))\n",
    "print(\"z1:\", z1.reshape(n_row, n_col))\n",
    "print(\"out:\", out.reshape(n_row, n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.33461428 0.3195711  0.318646   0.6182187  0.98775953]\n",
      " [0.9090064  0.31421646 0.49155873 0.07706822 0.7244915 ]\n",
      " [0.6314039  0.32546932 0.8983266  0.94506174 0.27454415]\n",
      " [0.9591644  0.72356695 0.8878879  0.83218116 0.61372954]\n",
      " [0.7061721  0.7718666  0.23344158 0.030182   0.3022792 ]\n",
      " [0.2440078  0.03983122 0.02183884 0.8521558  0.6460792 ]\n",
      " [0.27811128 0.06740171 0.47656724 0.90238565 0.5000209 ]\n",
      " [0.89489204 0.32485354 0.7970515  0.89360714 0.41858983]\n",
      " [0.70800966 0.7913499  0.22945935 0.9321512  0.19601052]\n",
      " [0.8166432  0.40817446 0.10786799 0.65642625 0.23842801]]\n",
      "dW: [[0.706791   0.4288014  0.4621686  0.5487347  0.76296836]\n",
      " [0.6571633  0.55811816 0.5101929  0.04239516 0.15132119]\n",
      " [0.45387363 0.8848482  0.7748484  0.66118443 0.15155412]\n",
      " [0.6620164  0.89205045 0.575946   0.32561484 0.63100654]\n",
      " [0.59820104 0.7982164  0.31105202 0.09974479 0.535854  ]\n",
      " [0.48336852 0.54772586 0.41365483 0.41299403 0.73340094]\n",
      " [0.37536603 0.1820588  0.9282085  0.6345236  0.31283966]\n",
      " [0.15130833 0.82264715 0.08971267 0.11143737 0.12239654]\n",
      " [0.6950927  0.21404184 0.34489614 0.12398342 0.70143896]\n",
      " [0.21017218 0.71129864 0.6534249  0.07655457 0.6474083 ]]\n",
      "out: [[0.32754636 0.3152831  0.31402433 0.6127314  0.98012984]\n",
      " [0.90243477 0.3086353  0.4864568  0.07664426 0.7229783 ]\n",
      " [0.6268652  0.31662083 0.8905781  0.9384499  0.2730286 ]\n",
      " [0.9525442  0.71464646 0.8821284  0.828925   0.6074195 ]\n",
      " [0.7001901  0.7638845  0.23033106 0.02918455 0.29692066]\n",
      " [0.23917411 0.03435396 0.01770229 0.84802586 0.6387452 ]\n",
      " [0.27435762 0.06558112 0.46728516 0.89604044 0.4968925 ]\n",
      " [0.893379   0.31662706 0.7961544  0.8924928  0.41736588]\n",
      " [0.70105875 0.7892095  0.22601038 0.93091136 0.18899612]\n",
      " [0.81454146 0.40106148 0.10133374 0.6556607  0.23195393]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "update_weights = mod.get_function(\"update_weights\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "epsilon = 0.01\n",
    "\n",
    "# Générer des données d'exemple\n",
    "W = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "dW = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros((n_row, n_col), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "W_gpu = drv.mem_alloc(W.nbytes)\n",
    "dW_gpu = drv.mem_alloc(dW.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(W_gpu, W)\n",
    "drv.memcpy_htod(dW_gpu, dW)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "update_weights(W_gpu, dW_gpu, out_gpu, np.float32(epsilon), np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"W:\", W.reshape(n_row, n_col))\n",
    "print(\"dW:\", dW.reshape(n_row, n_col))\n",
    "print(\"out:\", out.reshape(n_row, n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "update_bias = mod.get_function(\"update_bias\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "epsilon = 0.01\n",
    "\n",
    "# Générer des données d'exemple\n",
    "b = np.random.rand(n).astype(np.float32)\n",
    "db = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "b_gpu = drv.mem_alloc(b.nbytes)\n",
    "db_gpu = drv.mem_alloc(db.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(b_gpu, b)\n",
    "drv.memcpy_htod(db_gpu, db)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "update_bias(b_gpu, db_gpu, out_gpu, np.float32(epsilon), np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"b:\", b)\n",
    "print(\"db:\", db)\n",
    "print(\"out:\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
