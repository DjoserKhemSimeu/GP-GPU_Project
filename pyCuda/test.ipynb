{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succès : les résultats correspondent.\n",
      "[[32.06255  31.75959  32.929203 ... 32.913933 35.47173  31.566277]\n",
      " [30.625723 30.626526 29.449003 ... 32.03976  34.82396  30.636587]\n",
      " [32.023018 31.007334 29.233303 ... 33.957962 35.235214 29.332048]\n",
      " ...\n",
      " [30.753458 30.601162 29.704533 ... 32.029663 34.53249  29.389482]\n",
      " [31.237335 30.836004 30.722458 ... 33.61748  34.23421  29.546354]\n",
      " [32.609024 31.256659 32.494377 ... 33.186035 36.56704  32.060577]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "TILE_DIM = 16\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "matmul_kernel = mod.get_function(\"MatMul\")\n",
    "def test_matmul():\n",
    "    # Dimensions des matrices\n",
    "    ARows, ACols = , 128\n",
    "    BRows, BCols = 128, 64\n",
    "\n",
    "    # Création des matrices A et B aléatoires\n",
    "    A = np.random.rand(ARows, ACols).astype(np.float32)\n",
    "    B = np.random.rand(BRows, BCols).astype(np.float32)\n",
    "\n",
    "    # Matrice résultat C\n",
    "    C = np.zeros((ARows, BCols), dtype=np.float32)\n",
    "\n",
    "    # Allocation mémoire GPU\n",
    "    A_gpu = cuda.mem_alloc(A.nbytes)\n",
    "    B_gpu = cuda.mem_alloc(B.nbytes)\n",
    "    C_gpu = cuda.mem_alloc(C.nbytes)\n",
    "\n",
    "    # Copie des données vers le GPU\n",
    "    cuda.memcpy_htod(A_gpu, A)\n",
    "    cuda.memcpy_htod(B_gpu, B)\n",
    "\n",
    "    # Dimensions du bloc et de la grille\n",
    "    block = (TILE_DIM, TILE_DIM, 1)\n",
    "    grid = ((BCols + TILE_DIM - 1) // TILE_DIM, (ARows + TILE_DIM - 1) // TILE_DIM)\n",
    "\n",
    "    # Lancer le kernel\n",
    "    matmul_kernel(\n",
    "        A_gpu, B_gpu, C_gpu,\n",
    "        np.int32(ARows), np.int32(ACols), np.int32(BCols),\n",
    "        block=block, grid=grid\n",
    "    )\n",
    "\n",
    "    # Copier le résultat du GPU vers le CPU\n",
    "    cuda.memcpy_dtoh(C, C_gpu)\n",
    "\n",
    "    # Validation avec NumPy\n",
    "    C_reference = np.dot(A, B)\n",
    "\n",
    "    # Comparaison\n",
    "    if np.allclose(C, C_reference, atol=1e-5):\n",
    "        print(\"Succès : les résultats correspondent.\")\n",
    "    else:\n",
    "        print(\"Échec : les résultats ne correspondent pas.\")\n",
    "\n",
    "    print (C)\n",
    "if __name__ == \"__main__\":\n",
    "    test_matmul()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix:\n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19.]\n",
      " [20. 21. 22. 23. 24.]\n",
      " [25. 26. 27. 28. 29.]\n",
      " [30. 31. 32. 33. 34.]\n",
      " [35. 36. 37. 38. 39.]]\n",
      "Transposed Matrix:\n",
      "[[ 0.  8. 16. 24. 32.  0.  0.  0.]\n",
      " [ 1.  9. 17. 25. 33.  0.  0.  0.]\n",
      " [ 2. 10. 18. 26. 34.  0.  0.  0.]\n",
      " [ 3. 11. 19. 27. 35.  0.  0.  0.]\n",
      " [ 4. 12. 20. 28. 36.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "transpose = mod.get_function(\"transpose\")\n",
    "\n",
    "# Dimensions de la matrice\n",
    "nx, ny = 8, 5\n",
    "matrix = np.arange(nx * ny, dtype=np.float32).reshape(nx, ny)\n",
    "\n",
    "# Matrice d'entrée et de sortie\n",
    "input_matrix = np.array(matrix, dtype=np.float32)\n",
    "output_matrix = np.zeros_like(input_matrix.T)\n",
    "\n",
    "# Allocation de mémoire GPU\n",
    "input_gpu = drv.mem_alloc(input_matrix.nbytes)\n",
    "output_gpu = drv.mem_alloc(output_matrix.nbytes)\n",
    "\n",
    "# Copie des données vers le GPU\n",
    "drv.memcpy_htod(input_gpu, input_matrix)\n",
    "\n",
    "# Dimensions des blocs et de la grille\n",
    "block = (8, 8, 1)\n",
    "grid = ((nx + block[0] - 1) // block[0], (ny + block[1] - 1) // block[1])\n",
    "\n",
    "# Exécution du kernel\n",
    "transpose(input_gpu, output_gpu, np.uint32(nx), np.uint32(ny), block=block, grid=grid)\n",
    "\n",
    "# Copie du résultat vers le CPU\n",
    "drv.memcpy_dtoh(output_matrix, output_gpu)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Input Matrix:\")\n",
    "print(input_matrix)\n",
    "print(\"Transposed Matrix:\")\n",
    "print(output_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as drv\n",
    "drv.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# CUDA kernels as a string\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "update_weights = mod.get_function(\"update_weights\")\n",
    "update_bias = mod.get_function(\"update_bias\")\n",
    "\n",
    "# Parameters\n",
    "n_row = 4\n",
    "n_col = 3\n",
    "epsilon = 0.01\n",
    "\n",
    "# Initialize input data for weights\n",
    "W = np.random.rand(n_row, n_col).astype(np.float32)\n",
    "dW = np.random.rand(n_row, n_col).astype(np.float32)\n",
    "out_weights = np.zeros_like(W)\n",
    "\n",
    "# Initialize input data for biases\n",
    "b = np.random.rand(n_row).astype(np.float32)\n",
    "db = np.random.rand(n_row).astype(np.float32)\n",
    "out_bias = np.zeros_like(b)\n",
    "\n",
    "# Allocate device memory\n",
    "W_gpu = cuda.mem_alloc(W.nbytes)\n",
    "dW_gpu = cuda.mem_alloc(dW.nbytes)\n",
    "out_weights_gpu = cuda.mem_alloc(out_weights.nbytes)\n",
    "\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "db_gpu = cuda.mem_alloc(db.nbytes)\n",
    "out_bias_gpu = cuda.mem_alloc(out_bias.nbytes)\n",
    "\n",
    "# Copy data to device\n",
    "cuda.memcpy_htod(W_gpu, W)\n",
    "cuda.memcpy_htod(dW_gpu, dW)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "cuda.memcpy_htod(db_gpu, db)\n",
    "\n",
    "# Grid and block dimensions\n",
    "block_size = 32\n",
    "grid_size_weights = (n_row + block_size - 1) // block_size\n",
    "grid_size_bias = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Launch the update_weights kernel\n",
    "update_weights(W_gpu, dW_gpu, out_weights_gpu, \n",
    "               np.float32(epsilon), np.uint32(n_col), np.uint32(n_row), \n",
    "               block=(block_size, 1, 1), grid=(grid_size_weights, 1))\n",
    "\n",
    "# Launch the update_bias kernel\n",
    "update_bias(b_gpu, db_gpu, out_bias_gpu, \n",
    "            np.float32(epsilon), np.uint32(n_row), \n",
    "            block=(block_size, 1, 1), grid=(grid_size_bias, 1))\n",
    "\n",
    "# Copy results back to host\n",
    "cuda.memcpy_dtoh(out_weights, out_weights_gpu)\n",
    "cuda.memcpy_dtoh(out_bias, out_bias_gpu)\n",
    "\n",
    "# Print results\n",
    "print(\"Original weights:\\n\", W)\n",
    "print(\"Weight gradients:\\n\", dW)\n",
    "print(\"Updated weights:\\n\", out_weights)\n",
    "\n",
    "print(\"Original biases:\\n\", b)\n",
    "print(\"Bias gradients:\\n\", db)\n",
    "print(\"Updated biases:\\n\", out_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WX: [0.44234893 0.9506427  0.816055   0.76536775 0.7407418  0.6851173\n",
      " 0.17310758 0.22000445 0.38997483 0.09695225]\n",
      "b: [0.56816417 0.6982709  0.27382904 0.12475282 0.8154408  0.2197792\n",
      " 0.9319359  0.79871154 0.49813652 0.5260788 ]\n",
      "out: [1.0105131  1.6489136  1.089884   0.89012057 1.5561826  0.9048965\n",
      " 1.1050435  1.018716   0.88811135 0.6230311 ]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "add = mod.get_function(\"add\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "WX = np.random.rand(n).astype(np.float32)\n",
    "b = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "WX_gpu = drv.mem_alloc(WX.nbytes)\n",
    "b_gpu = drv.mem_alloc(b.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(WX_gpu, WX)\n",
    "drv.memcpy_htod(b_gpu, b)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "add(WX_gpu, b_gpu, out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"WX:\", WX)\n",
    "print(\"b:\", b)\n",
    "print(\"out:\", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuModuleGetFunction failed: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Charger le module compilé\u001b[39;00m\n\u001b[1;32m      7\u001b[0m mod \u001b[38;5;241m=\u001b[39m SourceModule(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel.cu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread(), options\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-std=c++11\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m sigmoid \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Définir les dimensions des données\u001b[39;00m\n\u001b[1;32m     11\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycuda/compiler.py:325\u001b[0m, in \u001b[0;36mCudaModule.get_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuModuleGetFunction failed: named symbol not found"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "sigmoid = mod.get_function(\"sigmoid\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "X = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "X_gpu = drv.mem_alloc(X.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(X_gpu, X)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "sigmoid(X_gpu, out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"X:\", X)\n",
    "print(\"out:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuModuleGetFunction failed: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m mod \u001b[38;5;241m=\u001b[39m SourceModule(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel.cu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread(), options\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-std=c++11\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m exp_scores \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m softmax_div \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax_div\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m reduce \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Définir les dimensions des données\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycuda/compiler.py:325\u001b[0m, in \u001b[0;36mCudaModule.get_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuModuleGetFunction failed: named symbol not found"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "exp_scores = mod.get_function(\"exp_scores\")\n",
    "softmax_div = mod.get_function(\"softmax_div\")\n",
    "reduce = mod.get_function(\"reduce\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "\n",
    "# Générer des données d'exemple\n",
    "X = np.random.rand(n).astype(np.float32)\n",
    "exp_scores_out = np.zeros(n, dtype=np.float32)\n",
    "softmax_out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "X_gpu = drv.mem_alloc(X.nbytes)\n",
    "exp_scores_gpu = drv.mem_alloc(exp_scores_out.nbytes)\n",
    "softmax_out_gpu = drv.mem_alloc(softmax_out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(X_gpu, X)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel exp_scores\n",
    "exp_scores(X_gpu, exp_scores_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Allouer de la mémoire pour la réduction\n",
    "temp_o = np.zeros(grid_size, dtype=np.float32)\n",
    "temp_o_gpu = drv.mem_alloc(temp_o.nbytes)\n",
    "drv.memcpy_dtoh(exp_scores_out,exp_scores_gpu )\n",
    "# Lancer le kernel reduce\n",
    "reduce(exp_scores_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * exp_scores_out.dtype.itemsize)\n",
    "\n",
    "# Réduire jusqu'à obtenir un seul résultat\n",
    "while grid_size > 1:\n",
    "    n = grid_size\n",
    "    grid_size = (n + block_size - 1) // block_size\n",
    "    reduce(temp_o_gpu, temp_o_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1), shared=block_size * temp_o.dtype.itemsize)\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(temp_o, temp_o_gpu)\n",
    "sum_exp_scores = temp_o[0]\n",
    "\n",
    "# Lancer le kernel softmax_div\n",
    "softmax_div(exp_scores_gpu, np.float32(sum_exp_scores), softmax_out_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(softmax_out, softmax_out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"X:\", X)\n",
    "print(\"exp_scores:\", exp_scores_out)\n",
    "print(\"softmax_out:\", softmax_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs: [[0.99579984 0.5844601  0.33910036 0.49083814 0.04340772]\n",
      " [0.58158123 0.03585429 0.240528   0.6326014  0.11575428]\n",
      " [0.49828082 0.6637241  0.93154335 0.36431745 0.38215813]\n",
      " [0.375357   0.35834676 0.72663724 0.08556011 0.49493223]\n",
      " [0.13543361 0.9085487  0.7289106  0.7970793  0.82219565]\n",
      " [0.32560155 0.8896485  0.9166291  0.33301947 0.16918373]\n",
      " [0.41824257 0.56029624 0.9962488  0.856241   0.6235782 ]\n",
      " [0.05035216 0.5427813  0.21113048 0.30545023 0.12998605]\n",
      " [0.0427946  0.06538843 0.15667163 0.78847784 0.96960974]\n",
      " [0.72211444 0.12521063 0.03835817 0.12172013 0.04630733]]\n",
      "y_true: [3 2 2 3 3 4 2 3 0 0]\n",
      "out: [[ 0.99579984  0.5844601   0.33910036 -0.50916183  0.04340772]\n",
      " [ 0.58158123  0.03585429 -0.759472    0.6326014   0.11575428]\n",
      " [ 0.49828082  0.6637241  -0.06845665  0.36431745  0.38215813]\n",
      " [ 0.375357    0.35834676  0.72663724 -0.9144399   0.49493223]\n",
      " [ 0.13543361  0.9085487   0.7289106  -0.20292068  0.82219565]\n",
      " [ 0.32560155  0.8896485   0.9166291   0.33301947 -0.83081627]\n",
      " [ 0.41824257  0.56029624 -0.00375122  0.856241    0.6235782 ]\n",
      " [ 0.05035216  0.5427813   0.21113048 -0.6945498   0.12998605]\n",
      " [-0.9572054   0.06538843  0.15667163  0.78847784  0.96960974]\n",
      " [-0.27788556  0.12521063  0.03835817  0.12172013  0.04630733]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_delta2 = mod.get_function(\"compute_delta2\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "num_classes = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "probs = np.random.rand(n, num_classes).astype(np.float32).flatten()\n",
    "y_true = np.random.randint(0, num_classes, n).astype(np.int32)\n",
    "out = np.zeros((n, num_classes), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "probs_gpu = drv.mem_alloc(probs.nbytes)\n",
    "y_true_gpu = drv.mem_alloc(y_true.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(probs_gpu, probs)\n",
    "drv.memcpy_htod(y_true_gpu, y_true)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_delta2(probs_gpu, y_true_gpu, out_gpu, np.int32(num_classes), np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"probs:\", probs.reshape(n, num_classes))\n",
    "print(\"y_true:\", y_true)\n",
    "print(\"out:\", out.reshape(n, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5701/1959673116.py:7: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu(112): warning #177-D: variable \"cpt\" was declared but never referenced\n",
      "\n",
      "\n",
      "  mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuModuleGetFunction failed: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Charger le module compilé\u001b[39;00m\n\u001b[1;32m      7\u001b[0m mod \u001b[38;5;241m=\u001b[39m SourceModule(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel.cu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread(), options\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-std=c++11\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m transpose \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Définir les dimensions des données\u001b[39;00m\n\u001b[1;32m     11\u001b[0m nx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycuda/compiler.py:325\u001b[0m, in \u001b[0;36mCudaModule.get_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuModuleGetFunction failed: named symbol not found"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "transpose = mod.get_function(\"transpose\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "nx = 4\n",
    "ny = 3\n",
    "\n",
    "# Générer des données d'exemple\n",
    "in_data = np.random.rand(nx, ny).astype(np.float32).flatten()\n",
    "out_data = np.zeros((ny, nx), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "in_gpu = drv.mem_alloc(in_data.nbytes)\n",
    "out_gpu = drv.mem_alloc(out_data.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(in_gpu, in_data)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = (16, 16, 1)\n",
    "grid_size = ((nx + block_size[0] - 1) // block_size[0], (ny + block_size[1] - 1) // block_size[1])\n",
    "\n",
    "# Lancer le kernel\n",
    "transpose(in_gpu, out_gpu, np.int32(nx), np.int32(ny), block=block_size, grid=grid_size)\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out_data, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Input matrix:\")\n",
    "print(in_data.reshape(nx, ny))\n",
    "print(\"Transposed matrix:\")\n",
    "print(out_data.reshape(ny, nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta2: [[9.6142030e-01 3.0700335e-01 8.9189118e-01 4.1769958e-01 8.9025557e-01]\n",
      " [4.5738357e-01 4.4079411e-01 6.6005242e-01 3.0428696e-01 7.6815319e-01]\n",
      " [3.7232322e-01 8.7078130e-01 3.5921535e-01 8.0106628e-01 6.6981053e-01]\n",
      " [3.1943254e-02 9.3578267e-01 6.9587469e-01 7.1866101e-01 4.1000751e-01]\n",
      " [1.0383261e-01 5.5926764e-01 4.8642412e-01 5.7543546e-01 7.5620651e-01]\n",
      " [3.1661743e-01 6.2468380e-01 8.2727581e-01 8.9099240e-01 8.4367818e-01]\n",
      " [4.6844202e-01 9.9610591e-01 4.8065805e-01 8.5665178e-01 6.9197929e-01]\n",
      " [7.5416809e-01 5.6775284e-01 6.2161505e-01 6.1623162e-01 5.4685020e-01]\n",
      " [5.8293217e-01 4.1602081e-01 3.6674398e-01 6.7336714e-01 1.7571448e-04]\n",
      " [8.1068653e-01 7.4544173e-01 6.8225920e-01 9.1511422e-01 6.9846046e-01]]\n",
      "out: [3.4682698 2.6306703 3.0731966 2.7922692 2.4811664 3.5032477 3.4938369\n",
      " 3.1066177 2.0392396 3.851962 ]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_db2 = mod.get_function(\"compute_db\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "delta2 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros(n_row, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "delta2_gpu = drv.mem_alloc(delta2.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(delta2_gpu, delta2)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_db2(delta2_gpu, out_gpu, np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"delta2:\", delta2.reshape(n_row, n_col))\n",
    "print(\"out:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta1: [[0.7229435  0.7954493  0.8658877  0.4679509  0.11311023]\n",
      " [0.06317025 0.54869056 0.38638923 0.02145014 0.17736492]\n",
      " [0.0269344  0.2003111  0.70101446 0.8266686  0.8926484 ]\n",
      " [0.1969392  0.7548375  0.36957484 0.50805146 0.82041967]\n",
      " [0.36999398 0.87921983 0.83923465 0.8131322  0.82500696]\n",
      " [0.789612   0.7683042  0.37008485 0.858343   0.58363235]\n",
      " [0.29557848 0.6855353  0.08448109 0.17226145 0.07810096]\n",
      " [0.75133127 0.92027587 0.8284486  0.53703386 0.27873248]\n",
      " [0.24790819 0.202245   0.43571332 0.567349   0.42123634]\n",
      " [0.50979376 0.99081457 0.17006712 0.8927718  0.26770726]]\n",
      "z1: [[0.18454328 0.08837061 0.74219215 0.1754119  0.11132077]\n",
      " [0.12701088 0.3263054  0.83915436 0.7290275  0.12473806]\n",
      " [0.70479375 0.6269907  0.59244823 0.99271196 0.83478093]\n",
      " [0.7525487  0.3677572  0.27071783 0.01353576 0.71301556]\n",
      " [0.4139638  0.31022763 0.47929388 0.556638   0.7373239 ]\n",
      " [0.6445809  0.8070839  0.17222428 0.19873093 0.25994596]\n",
      " [0.82396036 0.4758171  0.08085154 0.6257178  0.77216405]\n",
      " [0.29462793 0.46332905 0.2142767  0.26325002 0.10377345]\n",
      " [0.4536034  0.10591054 0.4047887  0.5288883  0.13110124]\n",
      " [0.19389987 0.8436496  0.23973867 0.14231753 0.8851326 ]]\n",
      "out: [[0.17920576 0.19847459 0.18919872 0.11609241 0.02819013]\n",
      " [0.01572904 0.1335851  0.08140535 0.00470869 0.04416919]\n",
      " [0.00596205 0.04546154 0.16073218 0.16307954 0.18839084]\n",
      " [0.04287283 0.18246998 0.09072133 0.12700705 0.18109618]\n",
      " [0.08864622 0.21460007 0.19820596 0.18831533 0.180577  ]\n",
      " [0.17823912 0.16390422 0.09183852 0.21248092 0.14347076]\n",
      " [0.06264645 0.16203804 0.0210858  0.03911064 0.01688138]\n",
      " [0.18381484 0.21815023 0.20475286 0.13195902 0.06949586]\n",
      " [0.05889523 0.05041973 0.10458533 0.13236322 0.10485788]\n",
      " [0.12625799 0.20837434 0.04191168 0.2220666  0.05535756]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "compute_delta1 = mod.get_function(\"compute_delta1\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "\n",
    "# Générer des données d'exemple\n",
    "delta1 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "z1 = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros((n_row, n_col), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "delta1_gpu = drv.mem_alloc(delta1.nbytes)\n",
    "z1_gpu = drv.mem_alloc(z1.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(delta1_gpu, delta1)\n",
    "drv.memcpy_htod(z1_gpu, z1)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "compute_delta1(delta1_gpu, z1_gpu, out_gpu, np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"delta1:\", delta1.reshape(n_row, n_col))\n",
    "print(\"z1:\", z1.reshape(n_row, n_col))\n",
    "print(\"out:\", out.reshape(n_row, n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.33461428 0.3195711  0.318646   0.6182187  0.98775953]\n",
      " [0.9090064  0.31421646 0.49155873 0.07706822 0.7244915 ]\n",
      " [0.6314039  0.32546932 0.8983266  0.94506174 0.27454415]\n",
      " [0.9591644  0.72356695 0.8878879  0.83218116 0.61372954]\n",
      " [0.7061721  0.7718666  0.23344158 0.030182   0.3022792 ]\n",
      " [0.2440078  0.03983122 0.02183884 0.8521558  0.6460792 ]\n",
      " [0.27811128 0.06740171 0.47656724 0.90238565 0.5000209 ]\n",
      " [0.89489204 0.32485354 0.7970515  0.89360714 0.41858983]\n",
      " [0.70800966 0.7913499  0.22945935 0.9321512  0.19601052]\n",
      " [0.8166432  0.40817446 0.10786799 0.65642625 0.23842801]]\n",
      "dW: [[0.706791   0.4288014  0.4621686  0.5487347  0.76296836]\n",
      " [0.6571633  0.55811816 0.5101929  0.04239516 0.15132119]\n",
      " [0.45387363 0.8848482  0.7748484  0.66118443 0.15155412]\n",
      " [0.6620164  0.89205045 0.575946   0.32561484 0.63100654]\n",
      " [0.59820104 0.7982164  0.31105202 0.09974479 0.535854  ]\n",
      " [0.48336852 0.54772586 0.41365483 0.41299403 0.73340094]\n",
      " [0.37536603 0.1820588  0.9282085  0.6345236  0.31283966]\n",
      " [0.15130833 0.82264715 0.08971267 0.11143737 0.12239654]\n",
      " [0.6950927  0.21404184 0.34489614 0.12398342 0.70143896]\n",
      " [0.21017218 0.71129864 0.6534249  0.07655457 0.6474083 ]]\n",
      "out: [[0.32754636 0.3152831  0.31402433 0.6127314  0.98012984]\n",
      " [0.90243477 0.3086353  0.4864568  0.07664426 0.7229783 ]\n",
      " [0.6268652  0.31662083 0.8905781  0.9384499  0.2730286 ]\n",
      " [0.9525442  0.71464646 0.8821284  0.828925   0.6074195 ]\n",
      " [0.7001901  0.7638845  0.23033106 0.02918455 0.29692066]\n",
      " [0.23917411 0.03435396 0.01770229 0.84802586 0.6387452 ]\n",
      " [0.27435762 0.06558112 0.46728516 0.89604044 0.4968925 ]\n",
      " [0.893379   0.31662706 0.7961544  0.8924928  0.41736588]\n",
      " [0.70105875 0.7892095  0.22601038 0.93091136 0.18899612]\n",
      " [0.81454146 0.40106148 0.10133374 0.6556607  0.23195393]]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "update_weights = mod.get_function(\"update_weights\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n_row = 10\n",
    "n_col = 5\n",
    "epsilon = 0.01\n",
    "\n",
    "# Générer des données d'exemple\n",
    "W = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "dW = np.random.rand(n_row, n_col).astype(np.float32).flatten()\n",
    "out = np.zeros((n_row, n_col), dtype=np.float32).flatten()\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "W_gpu = drv.mem_alloc(W.nbytes)\n",
    "dW_gpu = drv.mem_alloc(dW.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(W_gpu, W)\n",
    "drv.memcpy_htod(dW_gpu, dW)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n_row + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "update_weights(W_gpu, dW_gpu, out_gpu, np.float32(epsilon), np.int32(n_col), np.int32(n_row), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"W:\", W.reshape(n_row, n_col))\n",
    "print(\"dW:\", dW.reshape(n_row, n_col))\n",
    "print(\"out:\", out.reshape(n_row, n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Charger le module compilé\n",
    "mod = SourceModule(open(\"kernel.cu\").read(), options=['-std=c++11'])\n",
    "update_bias = mod.get_function(\"update_bias\")\n",
    "\n",
    "# Définir les dimensions des données\n",
    "n = 10\n",
    "epsilon = 0.01\n",
    "\n",
    "# Générer des données d'exemple\n",
    "b = np.random.rand(n).astype(np.float32)\n",
    "db = np.random.rand(n).astype(np.float32)\n",
    "out = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "# Allouer de la mémoire sur le GPU\n",
    "b_gpu = drv.mem_alloc(b.nbytes)\n",
    "db_gpu = drv.mem_alloc(db.nbytes)\n",
    "out_gpu = drv.mem_alloc(out.nbytes)\n",
    "\n",
    "# Copier les données sur le GPU\n",
    "drv.memcpy_htod(b_gpu, b)\n",
    "drv.memcpy_htod(db_gpu, db)\n",
    "\n",
    "# Définir la taille des blocs et des grilles\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Lancer le kernel\n",
    "update_bias(b_gpu, db_gpu, out_gpu, np.float32(epsilon), np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Copier les résultats du GPU vers l'hôte\n",
    "drv.memcpy_dtoh(out, out_gpu)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"b:\", b)\n",
    "print(\"db:\", db)\n",
    "print(\"out:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom du GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Nombre de multiprocesseurs: 20\n",
      "Nombre de threads par bloc: 1024\n",
      "Mémoire partagée par bloc: 49152\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "\n",
    "# Vérifier les ressources disponibles sur le GPU\n",
    "device = drv.Device(0)\n",
    "print(\"Nom du GPU:\", device.name())\n",
    "print(\"Nombre de multiprocesseurs:\", device.get_attribute(drv.device_attribute.MULTIPROCESSOR_COUNT))\n",
    "print(\"Nombre de threads par bloc:\", device.get_attribute(drv.device_attribute.MAX_THREADS_PER_BLOCK))\n",
    "print(\"Mémoire partagée par bloc:\", device.get_attribute(drv.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
